PROJECT DESCRIPTION

Urban flooding is significantly different from rural flooding as urbanization leads to developed catchments, which increases the flood peaks from 1.8 to 8 times and flood volumes by up to 6 times.
 Consequently, flooding Occurs very quickly due to faster flow times (in a matter of minutes).
 Urban areas are densely populated and people living in vulnerable areas suffer due to flooding, sometimes resulting in loss of life.
 It is not only the event of flooding but the secondary effect of exposure to infection also has its toll in terms of human suffering, loss of livelihood and, in extreme cases, loss of life. Increasing trend of urban flooding is a universal phenomenon and poses a great challenge to urban planners the world over.
 Predicting the extent of calamity requires lots of parameters like rainfall, vegetation etc. 
Improper disposal of solid waste, including domestic, commercial and industrial waste and dumping of construction debris into the drains also contributes significantly to reducing their capacities. 
It is imperative to take better operations and maintenance actions.   The main objective of this problem is to help the city managers or urban residents in for predicting the occurrence of urban flooding and can help them to take preventive

 

DATASET DESCRIPTION


	We have used Kerala Dataset for this project
	It consists of the data about  annual and monthly rainfall in Kerala between the years 1900-2018 and occurrence of flood in those years.

 

 
MODEL DESCRIPTION	


1.Logistic Regression:
A logistic regression model predicts a dependant data variable by analysing the relationship between one or more existing independent variables. For example, a logistic regression could be used to predict whether a political candidate will win or lose an election or whether a high school student will be admitted or not to a particular college. These binary outcomes allow straightforward decisions between two alternatives.
2.Random Forest:
Random Forest model grows and combines multiple decision trees to create a “forest.” A decision tree is another type of algorithm used to classify data. In very simple terms, you can think of it like a flowchart that draws a clear pathway to a decision or outcome; it starts at a single point and then branches off into two or more directions, with each branch of the decision tree offering different possible outcomes. 
3.Support Vector Machine;
SVM or Support Vector Machine is a linear model for classification and regression problems. It can solve linear and non-linear problems and work well for many practical problems. The idea of SVM is simple: The algorithm creates a line or a hyperplane which separates the data into classes.

4.XG Boost:
 XGBoost is an optimized distributed gradient boosting library designed for efficient and scalable training of machine learning models. It is an ensemble learning method that combines the predictions of multiple weak models to produce a stronger prediction. XGBoost stands for “Extreme Gradient Boosting” and it has become one of the most popular and widely used machine learning algorithms due to its ability to handle large datasets and its ability to achieve state-of-the-art performance in many machine learning tasks such as classification and regression.





SCREENSHOTS

                      
 
                             
                        

      


Model Accuracy:
 
